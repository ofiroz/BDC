import cv2
import numpy as np
import glob
import threading
import person_center
from matplotlib import pyplot as plt
import queue
from time import * # for sleep

# sample_frame = cv2.imread(path) 'WhatsApp Image 2020-04-27 at 11.53.36.jpeg'

# flag to every 10 frames - use only flag_to_ten[0]
flag_to_ten = [15] #15 frames

# do I need a img in for the first cell?
tmp = cv2.imread('WhatsApp Image 2020-04-27 at 11.53.36.jpeg') # TODO: change to a logo image "starting program"
tmp = cv2.cvtColor(tmp, cv2.COLOR_BGR2RGB)
frame_sample = [tmp]

#global samp

# current frame queue
# Q = queue.Queue(maxsize=1)
Q = queue.Queue()
Q.put(tmp)  # end of queue flag - check if qsize > 1
# Q.put(tmp)

'''
# Q.get()
if Q.empty():
    print("empty")
if Q.full():
    print("full")
# Q.put(5)
print("f")
# Q.put(54)
# Q.put(53)
# print(Q.get())
print(Q.get())

if Q.empty() is True:
    print("empty")

if Q.full is True:
    print("full")
'''


# checks for person in the frame every n seconds - uses person_center
def check_for_person():

    # cv2.waitKey(2000)
    # print(sample)
    # image_path = 'WhatsApp Image 2020-04-25 at 09.29.42.jpeg'

    #image_path = frame_sample[0]
    '''
    if Q.empty():
        print("-----line 56 ------")
        return
        cv2.waitKey(2000)
    # image_path = Q.get()
    '''
    # print("---line62 - access to frame_sample[0]----")
    #image_path = frame_sample[0]
    '''
    try: # TODO: USELESS
        image_path = frame_sample[0]
    except:
        print("----samp is None----")
        image_path = cv2.imread('WhatsApp Image 2020-04-27 at 11.53.36.jpeg')
    '''
    image_path = frame_sample[0]

    center, circle_radius = person_center.Center_coordinates(image_path)
    circle_radius = int(circle_radius)
    img = person_center.circle_center(image_path, center, circle_radius)

    # OpenCV represents RGB images as multi - dimensional NumPy arraysâ€¦ but in reverse order!
    # need to do is convert the image from BGR to RGB
    # img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)

    # TODO: circled sample - fixed colors issue
    plt.imshow(img, cmap='gray')
    plt.xticks([]), plt.yticks([])
    plt.show()

    # print("thread finished 'check_for_person'")


# test for timing - DELETE
def two_sec_count():
    print('Two seconds has passed')
    timer = threading.Timer(2, two_sec_count) # Call `two_sec_count` in 2 seconds.
    timer.start()


def readVideo(video_name):
    capture = cv2.VideoCapture(video_name)  # 0 for camera OR video_name
    if capture is None:
        print("Failed to read the image")
        exit
    # resized_capture = resizeimage.resize_thumbnail(capture, [640, 360])

    return capture


# get one video -> deliver motion detection
def video_processing(vid_name):
    cap = readVideo(vid_name)

    #    frame_width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))
    #    frame_height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))

    _, frame1 = cap.read()
    _, frame2 = cap.read()
    # print(frame1.shape)

    while cap.isOpened():
        # Major issue - SOLVED
        # returns an error while trying to read frames when video is over.
        if frame1 is None or frame2 is None:
            # print("success")
            return
        diff = cv2.absdiff(frame1, frame2)
        # print(frame1.shape)
        # print(frame2.shape)
        '''
        gray = cv2.cvtColor(diff, cv2.COLOR_BGR2GRAY)
        blur = cv2.GaussianBlur(gray, (5, 5), 0)
        _, thresh = cv2.threshold(blur, 18, 255,
                                  cv2.THRESH_BINARY)  # thresh of 5 reconize breathing. 2 will reconize pulse!!

        dilated = cv2.dilate(thresh, None, iterations=3)

        # cv2.imshow("feed", dilated)
        
        contours, _ = cv2.findContours(dilated, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)

        for contour in contours:
            (x, y, w, h) = cv2.boundingRect(contour)

            if cv2.contourArea(contour) < 1000:
                continue
            cv2.rectangle(frame1, (x, y), (x + w, y + h), (0, 150, 255), 2) # enlarge the image in the rectangle

        # cv2.drawContours(frame1, contours, -1, (0, 255, 0), 2)
        '''
        cv2.imshow("feed", frame1)
# ============================================================

        # sample every 15th frame for person detection
        if flag_to_ten[0] == 1:
            frame1 = cv2.cvtColor(frame1, cv2.COLOR_BGR2RGB)

            frame_sample[0] = frame1

            '''

            if Q.full():
                print("--------- line 170 -----------------")
                Q.get()
                cv2.waitKey(500)
         
            '''
            '''
            if Q.qsize() > 0:
                Q.get()
            Q.put(frame1)
            # cv2.imshow('dst', Q.get())
            #cv2.waitKey(2000)
            '''
            # TODO
            #print("----------------print the cur Q[0]----------------")
            #plt.imshow(Q.get(), cmap='gray')
            #plt.xticks([]), plt.yticks([])
            #plt.show()

            # cv2.imwrite('frame_sample.jpg', frame_sample)
            # print("Ten frame has passed")
            flag_to_ten[0] = 10
        else:
            flag_to_ten[0] = flag_to_ten[0] - 1

# ============================================================
        # cv2.imshow("feed", diff)
        # cv2.imshow("feed", dilated)

        frame1 = frame2
        _, frame2 = cap.read()

        if cv2.waitKey(40) == 27:
            break

    cv2.destroyAllWindows()
    cap.release()


# calls check_for_person every 5 seconds
def call_every_N_seconds():
    while True:
        check_for_person()
        print("========== WAIT <some (count&fix)> SECONDS ============")
        sleep(5)


def call_background_thread():
    two_sec_count()
    call_every_N_seconds()


# get ALL videos
def main_func():
    videos_name_list = []
    path = glob.glob('Video Samples/*.mp4')  # choose right format and location

    for f in path:  # check if gets names OR the videos (MP4)
        # print(tmp)
        videos_name_list.append(f)

    for vid in videos_name_list:
        print(vid) # video name
        video_processing(vid)



